# Backend APIs

Welcome to the backend API documentation! This guide provides everything you need to navigate, interact with, and manage your backend services. Whether you're performing health checks, managing documents, or querying data, this API has you covered. Letâ€™s dive into the details! ðŸš€


## [GET] /health
Quickly check if the server is alive and operational.

- **Response**:
    ```json
    {
        "up_time": 0,
        "status": "string"
    }
    ```
    - `up_time`: the server runtime in seconds.
    - `status`: `"healthy"` (all systems go) or `"unhealthy"` (time to troubleshoot).


## [GET] /services_health
Check the health of individual backend components. Breaks down the health of critical services to pinpoint issues. Useful for detailed diagnostics.
- **Response**:
    ```json
    {
        "backend": {
            "up_time": 0,
            "status": "string"
        },
        "datastore": {
            "up_time": 0,
            "status": "string"
        },
        "document_converter": {
            "up_time": 0,
            "status": "string"
        }
    }
    ```
    - Each service reports its `up_time` and `status`.
    - `status` values: `"healthy"` (great!) or `"unhealthy"` (investigate further).


## [GET] /has_document_uuid
Check if a specific document exists in the system. Confirms the presence of a document before running further operations.
- **Request**: Provide a `document_uuid` in the query string.
    ```
    /has_document_uuid?document_uuid=xxxxxxx
    ```

- **Response**: 
    ```json
    {
        "has_document": true
    }
    ```
    - `has_document`: `true` if the document exists, otherwise `false`.


## [GET] /embedding_length
Retrieve the length of your vector embeddings. Useful for understanding the dimensionality of embeddings generated by the backend.
- **Response**:
    ```json
    {
        "embedding_length": 0
    }
    ```
    - `embedding_length`: The number of dimensions in the embeddings.


## [POST] /add_document
Upload a document to the backend for processing. Adds a new document, generating embeddings and metadata for future queries.
- **Request**: Upload PDFs to use with `/query_document`. Expects `multipart/form-data`, see upload_file function in [**client.py**](../webui/src/remotes/client.py)

- **Response**:  
    ```json
    {
        "is_success": true,
        "message": "string"
    }
    ```
    - `is_success`: Confirms successful upload (`true`) or failure (`false`).
    - `message`: Contains error details if the upload fails; empty otherwise.

> [!NOTE]
> **Pro Tip: Large files or first-time uploads may take longer to process. Patience is key! â³**


## [POST] /query
Ask the backend questions and get answers via the LLM. Send queries to the LLM and receive real-time responses. Allows to get insights from embedded knowledge without referring to specific documents.
- **Request**: 
    ```json
    {
        "text": "string",
        "history": [
            {
                "role": "string",
                "content": "string"
            },
            ...
        ]
    }
    ```
    - `role`: Either `"user"` or `"assistant"` to track the conversation context.

- **Response**: it is a streamed response straight from Ollama. The text produced by the LLM can be obtained by the following:
    ```python
    _json = {"text": user_query, "history": {"role": "assistant", "content": "How can I help you?"}}
    stream_response = requests.post("http://localhost:8000/query", json=_json, stream=True)
    for chunk in stream_response.iter_lines():
        json_chunk = json.loads(chunk)
        text_response = json_chunk["message"]["content"]
    ```
    Each json is sent with a new line character, `\n` and contains the following:
    ```json
    {
        "model": "llama3.2",
        "created_at": "2023-08-04T08:52:19.385406455-07:00",
        "message": {
            "role": "assistant",
            "content": "The",
            "images": null
        },
        "done": false
    }
    ```
    as the Ollama implementation ([link](https://github.com/ollama/ollama/blob/main/docs/api.md#response-9)).

> [!TIP]
> See the code snippet in [**client.py**](../webui/src/remotes/client.py) for processing streamed responses.


## [POST] /query_document
Run a query against a specific document. Enables document-specific queries using the document's UUID.
- **Request**:
    ```json
    {
        "document_uuid": "string",
        "query_str": "string",
        "history": [
            {
                "role": "string",
                "content": "string"
            },
            ...
        ]
    }
    ```
    role is one of "user" or "assistant"
- **Response**: same as [**`/query`**](#post-query)


## [DELETE] /delete_all
Clear all stored documents and start fresh. Wipe all documents and their data. Ideal for resets or clearing space or when the embedding size changes.
- **Response**:
    ```json
    {
        "is_success": true,
        "error_message": ""
    }
    ```
    - `is_success`: Confirms if the operation succeeded.
    - `error_message`: Provides details if something goes wrong.


## [DELETE] /delete_document
Remove a specific document by its UUID.
- **Request**: query parameter
    ```
    /delete_document?=document_uuid=xxx
    ```

- **Response**: same format as [**`/delete_all`**](#delete-delete_all)


## [GET] /document_info
Retrieve information about stored documents. Get metadata for all documents or a specific one.
- **Request**: optional query parameter, if not provided the information of all documents stored will be returned. 
    ```
    /document_info?=document_uuid=xxx
    ```

- **Response**:
    ```json
    {
        "document_count": 0,
        "documents_info": [
            {
                "document_uuid": "string",
                "document_hash_str": "string",
                "document_filename": "string",
                "document_summary": "string"
            },
            ...
        ]
    }
    ```
    - `document_count`: Total number of stored documents.
    - `documents_info`: A list of documents with details like UUID, filename, and summaries.